{"cells":[{"cell_type":"code","source":["import os\n","path=\"/content/drive/MyDrive/COMP4211/PROJECT_xjs\"\n","os.chdir(path)\n","os.listdir(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"faOMCqmWkiwp","executionInfo":{"status":"ok","timestamp":1745919980655,"user_tz":-480,"elapsed":966,"user":{"displayName":"Jaccob Hui","userId":"09916266167726137624"}},"outputId":"cafff4ee-66a8-4e9e-b15f-578b6ebee92d"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['test.csv',\n"," 'test_model.py',\n"," 'sample_submission.csv',\n"," 'train.csv',\n"," 'train.py',\n"," 'ner_model',\n"," '__pycache__',\n"," 'train_bert_large32',\n"," 'tmp_trainer',\n"," 'wandb',\n"," 'train_bert_large64',\n"," 'network.py',\n"," 'data_loader.py',\n"," 'microsoft',\n"," 'submission.csv',\n"," 'unhandled_tokens.txt',\n"," 'skipped_rows.txt',\n"," 'COMP4211 PROJ.ipynb']"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["!pip install datasets hf_xet seqeval -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBJz43jkX229","executionInfo":{"status":"ok","timestamp":1745919990563,"user_tz":-480,"elapsed":9904,"user":{"displayName":"Jaccob Hui","userId":"09916266167726137624"}},"outputId":"6d8ade84-8df6-4410-86ef-6cc2446cbaae"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch.optim import AdamW\n","from transformers import  get_linear_schedule_with_warmup\n","from tqdm import tqdm\n","from data_loader import prepare_data_loaders\n","from network import get_model\n","from transformers import AutoTokenizer\n","import numpy as np\n","from sklearn.metrics import f1_score, accuracy_score\n","from torch.cuda.amp import autocast, GradScaler\n","from seqeval.metrics import f1_score as seq_f1_score\n"],"metadata":{"id":"OuaNTulXqk8E","executionInfo":{"status":"ok","timestamp":1745919999224,"user_tz":-480,"elapsed":8659,"user":{"displayName":"Jaccob Hui","userId":"09916266167726137624"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import random\n","random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)\n","torch.cuda.manual_seed_all(42)"],"metadata":{"id":"Bo37XQuKoPVK","executionInfo":{"status":"ok","timestamp":1745913766054,"user_tz":-480,"elapsed":2,"user":{"displayName":"Jaccob Hui","userId":"09916266167726137624"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# MODEL_NAME = \"microsoft/deberta-v3-large\"\n","# MODEL_NAME = \"FacebookAI/roberta-base\"\n","MODEL_NAME = \"google-bert/bert-base-cased\"\n","BATCH_SIZE = 32\n","EPOCHS = 3\n","USE_MIXED_PRECISION = False\n","\n","# Step 1: Load data loaders and tokenizer\n","# Set total batch size to 32, to be split across GPUs\n","train_loader, eval_loader, label2id, num_labels, tokenizer = prepare_data_loaders(\n","    data_path=\".\",\n","    model_name=MODEL_NAME,\n","    batch_size=BATCH_SIZE,\n","    # apply_mistag_correction=True\n",")\n","o_tag_id = label2id.get('O', None)\n","\n","# Step 2: Load model\n","model = get_model(MODEL_NAME, num_labels)\n","\n","# Step 3: Set up device and DataParallel\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 0\n","if num_gpus > 1:\n","    print(f\"Using {num_gpus} GPUs with DataParallel. Total batch size: {BATCH_SIZE}, per-GPU batch size: {BATCH_SIZE // num_gpus}\")\n","    model = nn.DataParallel(model)\n","else:\n","    print(f\"Using single GPU or CPU. Total batch size: {BATCH_SIZE}\")\n","model.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":900,"referenced_widgets":["0dbbf07c0594490a89e34f3f259745fd","c28fd98dcd454e50b522d3542acc3db9","92f77bc814d1466588d5bd39fe38b9ae","966e313d91744ea4a761edf7f217eab3","0ff1fd85718049309742c3a4bbffd454","9739a39cad914cceb85c413ba3a453a1","c4c93ae9aa864602a1e87e071186242a","6ee826df40db4cfdb013556780e05367","4cd2b4786a1b4bb0b09237d4b246eabb","8f4b9767b3c74e368e9fc3099703ad1a","f8c1c133e81148338f846fe86ecc4c9e","3dcb419ec030432f9bb884cd2684bc7d","34b6e46c287d4acb906a6f1a7382ee65","a574e3a5f4864cc080c03f4dd150835c","64a248d714ba4cbbb37d2735a69085e4","24e4550eee1644ab964e328ee4b39f35","54979a2ff15a47379d6db3eb46b07aff","006727c2a16b4ee3b4bc39fc3aaa7f2d","820b86844e094ff099f483c91539a593","662f6751e44c41709439174f88ee5ab9","1cae8488ea9843d8822ab8e4b81ff588","de3df0906c4b4557a3499798821b24c2"]},"id":"CIqZSoWYiLZR","executionInfo":{"status":"ok","timestamp":1745920569460,"user_tz":-480,"elapsed":21488,"user":{"displayName":"Jaccob Hui","userId":"09916266167726137624"}},"outputId":"c7ad9185-f3ad-472d-c2a0-78c16c552fac"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Skipped 2 rows with mismatched lengths. Details in 'skipped_rows.txt'\n","Split data: 31998 training samples, 8000 validation samples\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/31998 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dbbf07c0594490a89e34f3f259745fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dcb419ec030432f9bb884cd2684bc7d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Using single GPU or CPU. Total batch size: 32\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Step 4: Set up optimizer and scheduler\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","pretrain_params = [\n","    {\"params\": [p for n, p in model.named_parameters() if \"classifier\" not in n and not any(nd in n for nd in no_decay)], \"lr\": 2e-5},\n","    {\"params\": [p for n, p in model.named_parameters() if \"classifier\" not in n and any(nd in n for nd in no_decay)], \"lr\": 2e-5, \"weight_decay\": 0.0},\n","]\n","classifier_params = [\n","    {\"params\": [p for n, p in model.named_parameters() if \"classifier\" in n and not any(nd in n for nd in no_decay)], \"lr\": 2e-4},\n","    {\"params\": [p for n, p in model.named_parameters() if \"classifier\" in n and any(nd in n for nd in no_decay)], \"lr\": 2e-4, \"weight_decay\": 0.0},\n","]\n","optimizer = AdamW(pretrain_params + classifier_params, lr=2e-5, fused=True)\n","\n","total_steps = len(train_loader) * EPOCHS\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=EPOCHS*0.1, num_training_steps=total_steps)\n","scaler = torch.amp.GradScaler(\"cuda\" if torch.cuda.is_available() else \"cpu\", enabled=USE_MIXED_PRECISION)  # For mixed precision training\n","\n","# Step 5: Training loop\n","# Initialize variables for tracking the best model\n","best_val_f1 = 0\n","best_model_state = None\n","patience = 3\n","epochs_no_improve = 0\n","\n","for epoch in range(EPOCHS):\n","    # Training\n","    model.train()\n","    total_train_loss = 0\n","    train_preds = []\n","    train_labels_list = []\n","    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        with torch.amp.autocast(\"cuda\" if torch.cuda.is_available() else \"cpu\", enabled=USE_MIXED_PRECISION):\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        logits = outputs.logits\n","        preds = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n","        labels_np = labels.detach().cpu().numpy()\n","        flat_preds = preds.flatten()\n","        flat_labels = labels_np.flatten()\n","        mask = flat_labels != o_tag_id\n","        train_preds.extend(flat_preds[mask])\n","        train_labels_list.extend(flat_labels[mask])\n","\n","        loss = outputs.loss\n","        loss = loss.mean()  # Reduce loss to scalar for multi-GPU\n","        total_train_loss += loss.item()  # Log scalar loss\n","\n","        scaler.scale(loss).backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        scaler.step(optimizer)\n","        scaler.update()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","\n","    avg_train_loss = total_train_loss / len(train_loader)\n","    train_f1 = f1_score(train_labels_list, train_preds, average='macro')\n","    # train_f1 = seq_f1_score(train_labels_list, train_preds)\n","    train_acc = accuracy_score(train_labels_list, train_preds)\n","    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, F1: {train_f1:.4f}, Acc: {train_acc:.4f}\")\n","\n","    # Validation\n","    model.eval()\n","    total_eval_loss = 0\n","    val_preds = []\n","    val_labels_list = []\n","    with torch.no_grad():\n","        for batch in tqdm(eval_loader, desc=f\"Validation Epoch {epoch+1}\"):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            logits = outputs.logits\n","            preds = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n","            labels_np = labels.detach().cpu().numpy()\n","            flat_preds = preds.flatten()\n","            flat_labels = labels_np.flatten()\n","            mask = flat_labels != o_tag_id\n","            val_preds.extend(flat_preds[mask])\n","            val_labels_list.extend(flat_labels[mask])\n","\n","            loss = outputs.loss\n","            loss = loss.mean()  # Reduce loss to scalar for multi-GPU\n","            total_eval_loss += loss.item()  # Log scalar loss\n","\n","    avg_val_loss = total_eval_loss / len(eval_loader)\n","    val_f1 = f1_score(val_labels_list, val_preds, average='macro')\n","    # val_f1 = seq_f1_score(val_labels_list, val_preds)\n","\n","    val_acc = accuracy_score(val_labels_list, val_preds)\n","    print(f\"Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}, F1: {val_f1:.4f}, Acc: {val_acc:.4f}\")\n","\n","    # If the current validation loss is lower than the previous best, save the model state\n","    if val_f1 > best_val_f1:\n","        best_val_f1 = val_f1\n","        epochs_no_improve = 0\n","        # Save the state of the underlying model (not the DataParallel wrapper)\n","        best_model_state = model.module.state_dict().copy() if isinstance(model, nn.DataParallel) else model.state_dict().copy()\n","        print(f\"New best model found at epoch {epoch+1} with f1 score: {val_f1:.4f}\")\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break\n","\n","# After training, load the best model state\n","if best_model_state is not None:\n","    if isinstance(model, nn.DataParallel):\n","        model.module.load_state_dict(best_model_state)\n","    else:\n","        model.load_state_dict(best_model_state)\n","    print(f\"Loaded best model with f1 score: {best_val_f1}\")\n","\n","# Step 6: Save the best model and tokenizerz\n","# Save the underlying model (not the DataParallel wrapper)\n","model_to_save = model.module if isinstance(model, nn.DataParallel) else model\n","model_to_save.save_pretrained(MODEL_NAME + \"_best_model\")\n","tokenizer.save_pretrained(MODEL_NAME + \"_best_model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s402sqIDqmO2","executionInfo":{"status":"ok","timestamp":1745921550172,"user_tz":-480,"elapsed":976251,"user":{"displayName":"Jaccob Hui","userId":"09916266167726137624"}},"outputId":"f8b1cf58-b937-43b4-d0da-52e42c43c98c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Training Epoch 1: 100%|██████████| 1000/1000 [04:41<00:00,  3.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Training Loss: 0.1543, F1: 0.1153, Acc: 0.0110\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 1: 100%|██████████| 250/250 [00:29<00:00,  8.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Validation Loss: 0.0975, F1: 0.1467, Acc: 0.0118\n","New best model found at epoch 1 with f1 score: 0.1467\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch 2: 100%|██████████| 1000/1000 [04:41<00:00,  3.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2, Training Loss: 0.0834, F1: 0.1852, Acc: 0.0121\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 2: 100%|██████████| 250/250 [00:29<00:00,  8.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2, Validation Loss: 0.0920, F1: 0.1382, Acc: 0.0120\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch 3: 100%|██████████| 1000/1000 [04:41<00:00,  3.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3, Training Loss: 0.0684, F1: 0.2135, Acc: 0.0124\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 3: 100%|██████████| 250/250 [00:29<00:00,  8.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3, Validation Loss: 0.0914, F1: 0.1609, Acc: 0.0121\n","New best model found at epoch 3 with f1 score: 0.1609\n","Loaded best model with f1 score: 0.16090943292104154\n"]},{"output_type":"execute_result","data":{"text/plain":["('google-bert/bert-base-cased_best_model/tokenizer_config.json',\n"," 'google-bert/bert-base-cased_best_model/special_tokens_map.json',\n"," 'google-bert/bert-base-cased_best_model/vocab.txt',\n"," 'google-bert/bert-base-cased_best_model/added_tokens.json',\n"," 'google-bert/bert-base-cased_best_model/tokenizer.json')"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Manual save if interrupted\n","if best_model_state is not None:\n","    if isinstance(model, nn.DataParallel):\n","        model.module.load_state_dict(best_model_state)\n","    else:\n","        model.load_state_dict(best_model_state)\n","    print(f\"Loaded best model with f1 score: {best_val_f1}\")\n","model_to_save = model.module if isinstance(model, nn.DataParallel) else model\n","model_to_save.save_pretrained(MODEL_NAME + \"_best_model\")\n","tokenizer.save_pretrained(MODEL_NAME + \"_best_model\")"],"metadata":{"id":"L0LOi8El8mZc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745921570985,"user_tz":-480,"elapsed":1303,"user":{"displayName":"Jaccob Hui","userId":"09916266167726137624"}},"outputId":"1607b1eb-6822-4157-949c-3237e23c7054"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded best model with f1 score: 0.16090943292104154\n"]},{"output_type":"execute_result","data":{"text/plain":["('google-bert/bert-base-cased_best_model/tokenizer_config.json',\n"," 'google-bert/bert-base-cased_best_model/special_tokens_map.json',\n"," 'google-bert/bert-base-cased_best_model/vocab.txt',\n"," 'google-bert/bert-base-cased_best_model/added_tokens.json',\n"," 'google-bert/bert-base-cased_best_model/tokenizer.json')"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"_z-tlMFSmt1_","executionInfo":{"status":"ok","timestamp":1745917133502,"user_tz":-480,"elapsed":2,"user":{"displayName":"Jaccob Hui","userId":"09916266167726137624"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from ast import literal_eval\n","from datasets import Dataset\n","from transformers import AutoModelForTokenClassification, Trainer\n","import numpy as np\n","from data_loader import create_label_mappings, normalize_token\n","from data_loader import load_and_preprocess_data"],"metadata":{"id":"gmtDoBdcqjiR","executionInfo":{"status":"ok","timestamp":1745921573073,"user_tz":-480,"elapsed":2,"user":{"displayName":"Jaccob Hui","userId":"09916266167726137624"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def load_test_data(file_path):\n","    \"\"\"Load and preprocess test data, normalizing non-standard characters.\"\"\"\n","    try:\n","        df = pd.read_csv(file_path)\n","        df['Sentence'] = df['Sentence'].apply(literal_eval)\n","        df['Sentence'] = df['Sentence'].apply(lambda x: [normalize_token(w.strip()) for w in x if w.strip()])\n","        return df\n","    except Exception as e:\n","        print(f\"Failed to load test data from {file_path}: {e}\")\n","        raise\n","\n","def predict_and_save(model_path, test_ds, train_df, output_file=\"submission.csv\"):\n","    \"\"\"Predict NER tags and save submission.\"\"\"\n","    try:\n","        # Load model and tokenizer\n","        model = AutoModelForTokenClassification.from_pretrained(model_path)\n","        tokenizer = AutoTokenizer.from_pretrained(model_path)\n","    except Exception as e:\n","        print(f\"Failed to load model or tokenizer from {model_path}: {e}\")\n","        raise\n","\n","    # Load label mappings from training data\n","    try:\n","        label_list, label2id, id2label, _ = create_label_mappings(train_df)\n","    except Exception as e:\n","        print(f\"Failed to create label mappings: {e}\")\n","        id2label = model.config.id2label\n","        label2id = model.config.label2id\n","        if not id2label:\n","            print(\"Warning: id2label not found in model config. Using default labels.\")\n","            id2label = {i: f\"LABEL_{i}\" for i in range(model.config.num_labels)}\n","        label_list = list(label2id.keys())\n","\n","    def tokenize(examples):\n","        \"\"\"Tokenize sentences for prediction.\"\"\"\n","        tokenized = tokenizer(\n","            examples[\"Sentence\"],\n","            truncation=True,\n","            is_split_into_words=True,\n","            padding=\"max_length\",\n","            max_length=256,\n","            return_special_tokens_mask=True\n","        )\n","        return tokenized\n","\n","    try:\n","        # Tokenize test dataset\n","        tokenized_test = test_ds.map(tokenize, batched=True, remove_columns=[\"Sentence\", \"id\"])\n","    except Exception as e:\n","        print(f\"Failed to tokenize test dataset: {e}\")\n","        raise\n","\n","    # Initialize Trainer\n","    trainer = Trainer(model=model, tokenizer=tokenizer)\n","\n","    try:\n","        # Predict\n","        predictions = trainer.predict(tokenized_test)\n","        preds = np.argmax(predictions.predictions, axis=2)  # Convert logits to label IDs\n","    except Exception as e:\n","        print(f\"Prediction failed: {e}\")\n","        raise\n","\n","    # Process predictions\n","    final_preds = []\n","    test_df = test_ds.to_pandas()\n","\n","    for i in range(len(test_ds)):\n","        sentence = test_ds[i][\"Sentence\"]\n","        sentence_length = len(sentence)\n","        pred_ids = preds[i]\n","\n","        # Re-tokenize to get word_ids\n","        encoding = tokenizer(\n","            sentence,\n","            truncation=True,\n","            is_split_into_words=True,\n","            padding=False,\n","            max_length=256,\n","            return_special_tokens_mask=True\n","        )\n","        word_ids = encoding.word_ids()\n","\n","        # Align predictions with words\n","        word_to_tag = {}\n","        for idx, word_idx in enumerate(word_ids):\n","            if word_idx is None:\n","                continue\n","            if word_idx not in word_to_tag:\n","                pred_tag = id2label[pred_ids[idx]] if pred_ids[idx] != -100 else 'O'\n","                word_to_tag[word_idx] = pred_tag\n","\n","        # Assign tags to each word\n","        word_labels = []\n","        for word_idx in range(sentence_length):\n","            normalized = normalize_token(sentence[word_idx])\n","            if normalized in [\"'s\", ' ', '-', '\"', ''] or not normalized.strip():\n","                word_labels.append(\"O\")\n","            else:\n","                word_labels.append(word_to_tag.get(word_idx, \"O\"))\n","\n","        # Format as JSON-like string\n","        word_labels_str = str(word_labels)\n","        final_preds.append({'id': test_ds[i]['id'], 'NER Tag': word_labels_str})\n","\n","    # Save submission\n","    try:\n","        submission_df = pd.DataFrame(final_preds)\n","        # Validate lengths\n","        for idx, row in submission_df.iterrows():\n","            sentence = test_ds[idx][\"Sentence\"]\n","            predicted_tags = literal_eval(row[\"NER Tag\"])\n","            if len(predicted_tags) != len(sentence):\n","                print(f\"Warning: ID {row['id']} has mismatched lengths: \"\n","                      f\"Predicted {len(predicted_tags)}, Sentence {len(sentence)}\")\n","        submission_df.to_csv(output_file, index=False)\n","        print(f\"Submission saved to {output_file}\")\n","    except Exception as e:\n","        print(f\"Failed to save submission to {output_file}: {e}\")\n","        raise\n"],"metadata":{"id":"o1QQ1JimqU20","executionInfo":{"status":"ok","timestamp":1745921573725,"user_tz":-480,"elapsed":3,"user":{"displayName":"Jaccob Hui","userId":"09916266167726137624"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Test the best model and save predictions"],"metadata":{"id":"MDuu_dXGqaSo"}},{"cell_type":"code","source":["# Configuration\n","model_path = MODEL_NAME + \"_best_model\"\n","test_file = \"test.csv\"\n","train_file = \"train.csv\"\n","output_file = \"submission.csv\"\n","\n","# Load test and train data\n","test_df = load_test_data(test_file)\n","test_ds = Dataset.from_pandas(test_df)\n","print(f\"Test dataset size: {len(test_ds)}\")\n","\n","train_df = load_and_preprocess_data(train_file)\n","print(f\"Train dataset size: {len(train_df)}\")\n","\n","# Predict and save\n","predict_and_save(model_path, test_ds, train_df, output_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":153,"referenced_widgets":["21549e9394a14ca28709f61cf770e80e","0230c58f2dac4a82ad262ca89f68afe6","9422546cc1e94cf0a90c32f65342317f","3d35087b49d94043b11f74feea1e0a5a","334f4c73dd39434ebf25a68dc4d0f5c1","a52fb9858d2b4ce6adad2451049ae44b","ece25c025bb549528ae3d546bb86293a","7c1eb3a5dbbc4b69892ad3b8c4f87af1","75982fd59d384424b4477c8e397d8feb","c62ff27a1ee34fb09bf604e1e9eec618","da599e3d56484ebababa96b3d4769561"]},"id":"fML-XDAnqXqf","executionInfo":{"status":"ok","timestamp":1745921618507,"user_tz":-480,"elapsed":41843,"user":{"displayName":"Jaccob Hui","userId":"09916266167726137624"}},"outputId":"3e01cd53-9682-4626-a27a-60f32abe1b64"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Test dataset size: 5000\n","Skipped 2 rows with mismatched lengths. Details in 'skipped_rows.txt'\n","Train dataset size: 39998\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21549e9394a14ca28709f61cf770e80e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["<ipython-input-14-fccda80a700e>:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(model=model, tokenizer=tokenizer)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Submission saved to submission.csv\n"]}]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"uPZ_yJjFTW6C"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[],"mount_file_id":"1j8zJ31eSd1aveKsFw79IJzccCgYgj9mt","authorship_tag":"ABX9TyOE+7kygp5EiXhGraSB/bSS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0dbbf07c0594490a89e34f3f259745fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c28fd98dcd454e50b522d3542acc3db9","IPY_MODEL_92f77bc814d1466588d5bd39fe38b9ae","IPY_MODEL_966e313d91744ea4a761edf7f217eab3"],"layout":"IPY_MODEL_0ff1fd85718049309742c3a4bbffd454"}},"c28fd98dcd454e50b522d3542acc3db9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9739a39cad914cceb85c413ba3a453a1","placeholder":"​","style":"IPY_MODEL_c4c93ae9aa864602a1e87e071186242a","value":"Map: 100%"}},"92f77bc814d1466588d5bd39fe38b9ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ee826df40db4cfdb013556780e05367","max":31998,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4cd2b4786a1b4bb0b09237d4b246eabb","value":31998}},"966e313d91744ea4a761edf7f217eab3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f4b9767b3c74e368e9fc3099703ad1a","placeholder":"​","style":"IPY_MODEL_f8c1c133e81148338f846fe86ecc4c9e","value":" 31998/31998 [00:09&lt;00:00, 2474.15 examples/s]"}},"0ff1fd85718049309742c3a4bbffd454":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9739a39cad914cceb85c413ba3a453a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4c93ae9aa864602a1e87e071186242a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ee826df40db4cfdb013556780e05367":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cd2b4786a1b4bb0b09237d4b246eabb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f4b9767b3c74e368e9fc3099703ad1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8c1c133e81148338f846fe86ecc4c9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3dcb419ec030432f9bb884cd2684bc7d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34b6e46c287d4acb906a6f1a7382ee65","IPY_MODEL_a574e3a5f4864cc080c03f4dd150835c","IPY_MODEL_64a248d714ba4cbbb37d2735a69085e4"],"layout":"IPY_MODEL_24e4550eee1644ab964e328ee4b39f35"}},"34b6e46c287d4acb906a6f1a7382ee65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54979a2ff15a47379d6db3eb46b07aff","placeholder":"​","style":"IPY_MODEL_006727c2a16b4ee3b4bc39fc3aaa7f2d","value":"Map: 100%"}},"a574e3a5f4864cc080c03f4dd150835c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_820b86844e094ff099f483c91539a593","max":8000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_662f6751e44c41709439174f88ee5ab9","value":8000}},"64a248d714ba4cbbb37d2735a69085e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cae8488ea9843d8822ab8e4b81ff588","placeholder":"​","style":"IPY_MODEL_de3df0906c4b4557a3499798821b24c2","value":" 8000/8000 [00:02&lt;00:00, 3596.22 examples/s]"}},"24e4550eee1644ab964e328ee4b39f35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54979a2ff15a47379d6db3eb46b07aff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"006727c2a16b4ee3b4bc39fc3aaa7f2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"820b86844e094ff099f483c91539a593":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"662f6751e44c41709439174f88ee5ab9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1cae8488ea9843d8822ab8e4b81ff588":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de3df0906c4b4557a3499798821b24c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21549e9394a14ca28709f61cf770e80e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0230c58f2dac4a82ad262ca89f68afe6","IPY_MODEL_9422546cc1e94cf0a90c32f65342317f","IPY_MODEL_3d35087b49d94043b11f74feea1e0a5a"],"layout":"IPY_MODEL_334f4c73dd39434ebf25a68dc4d0f5c1"}},"0230c58f2dac4a82ad262ca89f68afe6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a52fb9858d2b4ce6adad2451049ae44b","placeholder":"​","style":"IPY_MODEL_ece25c025bb549528ae3d546bb86293a","value":"Map: 100%"}},"9422546cc1e94cf0a90c32f65342317f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c1eb3a5dbbc4b69892ad3b8c4f87af1","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75982fd59d384424b4477c8e397d8feb","value":5000}},"3d35087b49d94043b11f74feea1e0a5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c62ff27a1ee34fb09bf604e1e9eec618","placeholder":"​","style":"IPY_MODEL_da599e3d56484ebababa96b3d4769561","value":" 5000/5000 [00:01&lt;00:00, 4591.97 examples/s]"}},"334f4c73dd39434ebf25a68dc4d0f5c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a52fb9858d2b4ce6adad2451049ae44b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ece25c025bb549528ae3d546bb86293a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c1eb3a5dbbc4b69892ad3b8c4f87af1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75982fd59d384424b4477c8e397d8feb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c62ff27a1ee34fb09bf604e1e9eec618":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da599e3d56484ebababa96b3d4769561":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}